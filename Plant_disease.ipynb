{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "iCvVoDc-SnfU",
        "outputId": "fd37653d-f15c-4df3-8400-21d5624ead73"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-62aa34fd-936b-4160-b707-adeba9046d1e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-62aa34fd-936b-4160-b707-adeba9046d1e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Install Kaggle API for dataset download\n",
        "!pip install -q kaggle\n",
        "\n",
        "# Install TensorFlow (should be pre-installed in Colab, but ensure latest version)\n",
        "!pip install -q tensorflow\n",
        "\n",
        "# Upload kaggle.json (download from Kaggle: Account > Settings > API > Create New Token)\n",
        "from google.colab import files\n",
        "files.upload()  # This opens a file picker; upload kaggle.json\n",
        "\n",
        "# Set up Kaggle credentials securely\n",
        "!mkdir -p ~/.kaggle  # Create .kaggle directory\n",
        "!cp kaggle.json ~/.kaggle/  # Copy API token\n",
        "!chmod 600 ~/.kaggle/kaggle.json  # Restrict permissions to owner only\n",
        "\n",
        "# Optional: Mount Google Drive to save models and results\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')  # Follow prompt to authenticate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the dataset from Kaggle\n",
        "!kaggle datasets download -d vipoooool/new-plant-diseases-dataset\n",
        "\n",
        "# Unzip the dataset quietly to /content/\n",
        "!unzip -q new-plant-diseases-dataset.zip\n",
        "\n",
        "# Verify directory structure to ensure correct extraction\n",
        "import os\n",
        "train_dir = '/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train'\n",
        "valid_dir = '/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/valid'\n",
        "test_dir = '/content/test/test'\n",
        "\n",
        "# Print basic stats for report (dataset description)\n",
        "print(f\"Number of training classes: {len(os.listdir(train_dir))}\")  # Should be 38\n",
        "print(f\"Training images: {sum(len(files) for _, _, files in os.walk(train_dir))}\")  # ~70,295\n",
        "print(f\"Validation images: {sum(len(files) for _, _, files in os.walk(valid_dir))}\")  # ~17,572\n",
        "print(f\"Test images: {len(os.listdir(test_dir))}\")  # ~3,662"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hfigyYMJZXKN",
        "outputId": "e34d1d6d-6727-439c-fa07-08e8c24ae03e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/vipoooool/new-plant-diseases-dataset\n",
            "License(s): copyright-authors\n",
            "Downloading new-plant-diseases-dataset.zip to /content\n",
            " 98% 2.64G/2.70G [00:29<00:01, 38.3MB/s]\n",
            "100% 2.70G/2.70G [00:29<00:00, 96.8MB/s]\n",
            "Number of training classes: 38\n",
            "Training images: 70295\n",
            "Validation images: 17572\n",
            "Test images: 33\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(\"Full directory structure:\")\n",
        "for root, dirs, files in os.walk('/content/New Plant Diseases Dataset(Augmented)/'):\n",
        "    print(f\"{root}: {len(dirs)} dirs, {len(files)} files\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61I8PlFAcJok",
        "outputId": "9ef8804a-46b9-4f54-f202-112c827e01e0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full directory structure:\n",
            "/content/New Plant Diseases Dataset(Augmented)/: 1 dirs, 0 files\n",
            "/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented): 2 dirs, 0 files\n",
            "/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/valid: 38 dirs, 0 files\n",
            "/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/valid/Tomato___Tomato_Yellow_Leaf_Curl_Virus: 0 dirs, 490 files\n",
            "/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/valid/Tomato___Bacterial_spot: 0 dirs, 425 files\n",
            "/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/valid/Cherry_(including_sour)___Powdery_mildew: 0 dirs, 421 files\n",
            "/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/valid/Apple___Cedar_apple_rust: 0 dirs, 440 files\n",
            "/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/valid/Grape___Esca_(Black_Measles): 0 dirs, 480 files\n",
            "/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/valid/Tomato___Tomato_mosaic_virus: 0 dirs, 448 files\n",
            "/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/valid/Corn_(maize)___healthy: 0 dirs, 465 files\n",
            "/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/valid/Apple___Apple_scab: 0 dirs, 504 files\n",
            "/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/valid/Blueberry___healthy: 0 dirs, 454 files\n",
            "/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/valid/Tomato___Leaf_Mold: 0 dirs, 470 files\n",
            "/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/valid/Tomato___healthy: 0 dirs, 481 files\n",
            "/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/valid/Corn_(maize)___Common_rust_: 0 dirs, 477 files\n",
            "/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/valid/Tomato___Late_blight: 0 dirs, 463 files\n",
            "/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/valid/Soybean___healthy: 0 dirs, 505 files\n",
            "/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/valid/Potato___Early_blight: 0 dirs, 485 files\n",
            "/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/valid/Potato___Late_blight: 0 dirs, 485 files\n",
            "/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/valid/Strawberry___healthy: 0 dirs, 456 files\n",
            "/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/valid/Corn_(maize)___Northern_Leaf_Blight: 0 dirs, 477 files\n",
            "/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/valid/Grape___Black_rot: 0 dirs, 472 files\n",
            "/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/valid/Peach___healthy: 0 dirs, 432 files\n",
            "/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/valid/Cherry_(including_sour)___healthy: 0 dirs, 456 files\n",
            "/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/valid/Raspberry___healthy: 0 dirs, 445 files\n",
            "/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/valid/Tomato___Target_Spot: 0 dirs, 457 files\n",
            "/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/valid/Potato___healthy: 0 dirs, 456 files\n",
            "/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/valid/Tomato___Septoria_leaf_spot: 0 dirs, 436 files\n",
            "/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/valid/Peach___Bacterial_spot: 0 dirs, 459 files\n",
            "/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/valid/Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot: 0 dirs, 410 files\n",
            "/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/valid/Strawberry___Leaf_scorch: 0 dirs, 444 files\n",
            "/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/valid/Pepper,_bell___healthy: 0 dirs, 497 files\n",
            "/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/valid/Grape___healthy: 0 dirs, 423 files\n",
            "/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/valid/Squash___Powdery_mildew: 0 dirs, 434 files\n",
            "/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/valid/Pepper,_bell___Bacterial_spot: 0 dirs, 478 files\n",
            "/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/valid/Grape___Leaf_blight_(Isariopsis_Leaf_Spot): 0 dirs, 430 files\n",
            "/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/valid/Tomato___Early_blight: 0 dirs, 480 files\n",
            "/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/valid/Apple___Black_rot: 0 dirs, 497 files\n",
            "/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/valid/Apple___healthy: 0 dirs, 502 files\n",
            "/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/valid/Orange___Haunglongbing_(Citrus_greening): 0 dirs, 503 files\n",
            "/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/valid/Tomato___Spider_mites Two-spotted_spider_mite: 0 dirs, 435 files\n",
            "/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train: 38 dirs, 0 files\n",
            "/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train/Tomato___Tomato_Yellow_Leaf_Curl_Virus: 0 dirs, 1961 files\n",
            "/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train/Tomato___Bacterial_spot: 0 dirs, 1702 files\n",
            "/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train/Cherry_(including_sour)___Powdery_mildew: 0 dirs, 1683 files\n",
            "/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train/Apple___Cedar_apple_rust: 0 dirs, 1760 files\n",
            "/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train/Grape___Esca_(Black_Measles): 0 dirs, 1920 files\n",
            "/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train/Tomato___Tomato_mosaic_virus: 0 dirs, 1790 files\n",
            "/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train/Corn_(maize)___healthy: 0 dirs, 1859 files\n",
            "/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train/Apple___Apple_scab: 0 dirs, 2016 files\n",
            "/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train/Blueberry___healthy: 0 dirs, 1816 files\n",
            "/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train/Tomato___Leaf_Mold: 0 dirs, 1882 files\n",
            "/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train/Tomato___healthy: 0 dirs, 1926 files\n",
            "/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train/Corn_(maize)___Common_rust_: 0 dirs, 1907 files\n",
            "/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train/Tomato___Late_blight: 0 dirs, 1851 files\n",
            "/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train/Soybean___healthy: 0 dirs, 2022 files\n",
            "/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train/Potato___Early_blight: 0 dirs, 1939 files\n",
            "/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train/Potato___Late_blight: 0 dirs, 1939 files\n",
            "/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train/Strawberry___healthy: 0 dirs, 1824 files\n",
            "/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train/Corn_(maize)___Northern_Leaf_Blight: 0 dirs, 1908 files\n",
            "/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train/Grape___Black_rot: 0 dirs, 1888 files\n",
            "/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train/Peach___healthy: 0 dirs, 1728 files\n",
            "/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train/Cherry_(including_sour)___healthy: 0 dirs, 1826 files\n",
            "/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train/Raspberry___healthy: 0 dirs, 1781 files\n",
            "/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train/Tomato___Target_Spot: 0 dirs, 1827 files\n",
            "/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train/Potato___healthy: 0 dirs, 1824 files\n",
            "/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train/Tomato___Septoria_leaf_spot: 0 dirs, 1745 files\n",
            "/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train/Peach___Bacterial_spot: 0 dirs, 1838 files\n",
            "/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train/Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot: 0 dirs, 1642 files\n",
            "/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train/Strawberry___Leaf_scorch: 0 dirs, 1774 files\n",
            "/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train/Pepper,_bell___healthy: 0 dirs, 1988 files\n",
            "/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train/Grape___healthy: 0 dirs, 1692 files\n",
            "/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train/Squash___Powdery_mildew: 0 dirs, 1736 files\n",
            "/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train/Pepper,_bell___Bacterial_spot: 0 dirs, 1913 files\n",
            "/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train/Grape___Leaf_blight_(Isariopsis_Leaf_Spot): 0 dirs, 1722 files\n",
            "/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train/Tomato___Early_blight: 0 dirs, 1920 files\n",
            "/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train/Apple___Black_rot: 0 dirs, 1987 files\n",
            "/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train/Apple___healthy: 0 dirs, 2008 files\n",
            "/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train/Orange___Haunglongbing_(Citrus_greening): 0 dirs, 2010 files\n",
            "/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train/Tomato___Spider_mites Two-spotted_spider_mite: 0 dirs, 1741 files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import essential libraries for deep learning and visualization\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, applications  # For model building and transfer learning\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator  # For data loading/augmentation\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report, confusion_matrix, f1_score  # For results\n",
        "import seaborn as sns  # For confusion matrix visualization\n",
        "import pandas as pd  # For comparison tables\n",
        "import os\n",
        "\n",
        "# Define constants for reproducibility and clarity\n",
        "IMG_SIZE = (224, 224)  # Standard for transfer learning (e.g., ResNet, VGG); resizes from 256x256\n",
        "BATCH_SIZE = 32  # Suitable for Colab T4 GPU (~16GB VRAM)\n",
        "NUM_CLASSES = 38  # Fixed: 38 plant disease/health classes\n",
        "EPOCHS = 20  # Initial; will use early stopping to prevent overfitting\n",
        "SEED = 42  # For reproducible shuffling/splits"
      ],
      "metadata": {
        "id": "UeRDcyWBc-ig"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import additional library for class weight computation\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# Define directory paths (adjusted based on structure)\n",
        "train_dir = '/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train'\n",
        "valid_dir = '/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/valid'\n",
        "# Test directory not found; will use valid for evaluation or split later if needed\n",
        "test_dir = None  # Placeholder; revisit if test set is located\n",
        "\n",
        "# Function to remove corrupted images (cleansing)\n",
        "def remove_corrupted_images(directory):\n",
        "    num_removed = 0\n",
        "    if directory:  # Only proceed if directory exists\n",
        "        for subdir, _, files in os.walk(directory):\n",
        "            for file in files:\n",
        "                file_path = os.path.join(subdir, file)\n",
        "                try:\n",
        "                    img = tf.io.read_file(file_path)\n",
        "                    tf.image.decode_jpeg(img)  # Attempt to decode\n",
        "                except:\n",
        "                    os.remove(file_path)\n",
        "                    num_removed += 1\n",
        "    print(f\"Removed {num_removed} corrupted images from {directory if directory else 'no directory'}.\")\n",
        "\n",
        "# Clean train and valid sets\n",
        "remove_corrupted_images(train_dir)\n",
        "remove_corrupted_images(valid_dir)\n",
        "\n",
        "# Data generators with augmentation and normalization\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,  # Normalize pixel values to [0,1]\n",
        "    rotation_range=20,  # Rotate up to 20 degrees for robustness\n",
        "    width_shift_range=0.2,  # Shift width by 20%\n",
        "    height_shift_range=0.2,  # Shift height by 20%\n",
        "    shear_range=0.2,  # Shear transformation\n",
        "    zoom_range=0.2,  # Zoom in/out by 20%\n",
        "    horizontal_flip=True,  # Flip horizontally\n",
        "    fill_mode='nearest',  # Fill gaps with nearest pixel\n",
        "    validation_split=0.1  # Reserve 10% of train for a holdout test if needed\n",
        ")\n",
        "\n",
        "valid_datagen = ImageDataGenerator(rescale=1./255)  # Only normalize validation\n",
        "\n",
        "# Load and preprocess datasets\n",
        "train_ds = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=IMG_SIZE,  # Resize to 224x224\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',  # Multi-class with one-hot encoding\n",
        "    subset='training',  # Use 90% of train\n",
        "    seed=SEED\n",
        ")\n",
        "\n",
        "valid_ds = valid_datagen.flow_from_directory(\n",
        "    valid_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False,  # Keep order for evaluation\n",
        "    seed=SEED\n",
        ")\n",
        "\n",
        "# Optional: Create a holdout test set from train (10% split)\n",
        "test_ds = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    subset='validation',  # 10% holdout\n",
        "    seed=SEED,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Compute class weights to handle imbalance\n",
        "train_classes = train_ds.classes\n",
        "class_weights = compute_class_weight(\n",
        "    'balanced',\n",
        "    classes=np.unique(train_classes),\n",
        "    y=train_classes\n",
        ")\n",
        "class_weights = dict(enumerate(class_weights))\n",
        "print(\"Class weights:\", class_weights)\n",
        "\n",
        "# Verify dataset sizes\n",
        "print(f\"Train batches: {len(train_ds)}\")\n",
        "print(f\"Validation batches: {len(valid_ds)}\")\n",
        "print(f\"Test batches: {len(test_ds) if test_ds else 'Not created'}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z93BvnMadyfH",
        "outputId": "11cc87e7-4ea8-4f82-b270-4c6b38d28453"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removed 0 corrupted images from /content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train.\n",
            "Removed 0 corrupted images from /content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/valid.\n",
            "Found 63282 images belonging to 38 classes.\n",
            "Found 17572 images belonging to 38 classes.\n",
            "Found 7013 images belonging to 38 classes.\n",
            "Class weights: {0: np.float64(0.9175293605915615), 1: np.float64(0.9308640522491247), 2: np.float64(1.0513357256778308), 3: np.float64(0.9210817419655333), 4: np.float64(1.0185417672621921), 5: np.float64(1.0992183428869202), 6: np.float64(1.0129658086822897), 7: np.float64(1.1267359874652803), 8: np.float64(0.9698985378414002), 9: np.float64(0.9693339868880583), 10: np.float64(0.9948122995661196), 11: np.float64(0.9795975232198142), 12: np.float64(0.9637244152046783), 13: np.float64(1.074397283531409), 14: np.float64(1.0934443791685386), 15: np.float64(0.9205725757179017), 16: np.float64(1.0062331054221656), 17: np.float64(1.0702543634149642), 18: np.float64(0.9670823399963323), 19: np.float64(0.9303440164657454), 20: np.float64(0.9537891119551456), 21: np.float64(0.9537891119551456), 22: np.float64(1.0141996281812937), 23: np.float64(1.0388744787733526), 24: np.float64(0.9150086755349913), 25: np.float64(1.0654611576926962), 26: np.float64(1.042777576376759), 27: np.float64(1.0141996281812937), 28: np.float64(1.0870207503091933), 29: np.float64(0.9637244152046783), 30: np.float64(0.9995893094079737), 31: np.float64(0.9830671720623874), 32: np.float64(1.0600355120774565), 33: np.float64(1.0627414100023511), 34: np.float64(1.0123500239961607), 35: np.float64(0.9435216937527956), 36: np.float64(1.0337155738508281), 37: np.float64(0.9603897286468767)}\n",
            "Train batches: 1978\n",
            "Validation batches: 550\n",
            "Test batches: 220\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define callbacks for training optimization\n",
        "callbacks = [\n",
        "    keras.callbacks.EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=5,\n",
        "        restore_best_weights=True  # Restore best model weights\n",
        "    ),\n",
        "    keras.callbacks.ReduceLROnPlateau(\n",
        "        monitor='val_loss',\n",
        "        factor=0.2,\n",
        "        patience=3  # Reduce LR if no improvement\n",
        "    ),\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        '/content/drive/MyDrive/plant_model_{epoch}.h5',\n",
        "        save_best_only=True  # Save only the best model\n",
        "    )\n",
        "]\n",
        "\n",
        "# Function to build, compile, train, and evaluate a model\n",
        "def build_train_evaluate_model(base_model=None, name='Model'):\n",
        "    if base_model:\n",
        "        base_model.trainable = False  # Freeze base layers for transfer learning\n",
        "        model = keras.Sequential([\n",
        "            base_model,\n",
        "            layers.GlobalAveragePooling2D(),  # Reduce spatial dimensions\n",
        "            layers.Dense(128, activation='relu'),  # Dense layer for feature extraction\n",
        "            layers.Dropout(0.5),  # Prevent overfitting\n",
        "            layers.Dense(NUM_CLASSES, activation='softmax')  # Output layer for 38 classes\n",
        "        ])\n",
        "    else:  # Custom CNN\n",
        "        model = keras.Sequential([\n",
        "            layers.Conv2D(32, 3, activation='relu', input_shape=(*IMG_SIZE, 3)),  # Initial conv layer\n",
        "            layers.MaxPooling2D(),  # Reduce spatial size\n",
        "            layers.Conv2D(64, 3, activation='relu'),  # Deeper conv layer\n",
        "            layers.MaxPooling2D(),\n",
        "            layers.Conv2D(128, 3, activation='relu'),\n",
        "            layers.MaxPooling2D(),\n",
        "            layers.Flatten(),  # Flatten for dense layers\n",
        "            layers.Dense(128, activation='relu'),\n",
        "            layers.Dropout(0.5),\n",
        "            layers.Dense(NUM_CLASSES, activation='softmax')\n",
        "        ])\n",
        "\n",
        "    model.compile(\n",
        "        optimizer='adam',  # Adaptive optimizer for efficient training\n",
        "        loss='categorical_crossentropy',  # Multi-class loss\n",
        "        metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]  # Track performance\n",
        "    )\n",
        "\n",
        "    history = model.fit(\n",
        "        train_ds,\n",
        "        epochs=EPOCHS,\n",
        "        validation_data=valid_ds,\n",
        "        class_weight=class_weights,  # Apply imbalance weights\n",
        "        callbacks=callbacks\n",
        "    )\n",
        "\n",
        "    # Evaluate on validation set\n",
        "    val_preds = np.argmax(model.predict(valid_ds), axis=1)\n",
        "    val_true = np.argmax([y for x, y in valid_ds], axis=1)  # Extract true labels\n",
        "    print(f\"{name} - Classification Report:\\n\", classification_report(val_true, val_preds, target_names=class_names[:5]))  # Sample 5 classes\n",
        "    return model, history\n",
        "\n",
        "# Define and train models with justifications\n",
        "# 1. Custom CNN (Baseline)\n",
        "# Justification: Simple architecture to understand convolutions and pooling. Suitable as a baseline but may struggle with complex features due to limited depth. ReLU for non-linearity, softmax for multi-class output.\n",
        "model1, history1 = build_train_evaluate_model(name='Custom CNN')\n",
        "\n",
        "# 2. VGG16 (Transfer Learning)\n",
        "# Justification: Pre-trained on ImageNet, deep with uniform 3x3 convs for fine details. Frozen base leverages learned features; ReLU and softmax for consistency.\n",
        "vgg_base = applications.VGG16(weights='imagenet', include_top=False, input_shape=(*IMG_SIZE, 3))\n",
        "model2, history2 = build_train_evaluate_model(vgg_base, 'VGG16')\n",
        "\n",
        "# 3. ResNet50 (Transfer Learning)\n",
        "# Justification: Uses residual connections to prevent vanishing gradients in deep nets. Pre-trained on ImageNet, ideal for complex plant disease patterns; ReLU and softmax.\n",
        "resnet_base = applications.ResNet50(weights='imagenet', include_top=False, input_shape=(*IMG_SIZE, 3))\n",
        "model3, history3 = build_train_evaluate_model(resnet_base, 'ResNet50')\n",
        "\n",
        "# 4. EfficientNetB0 (Transfer Learning)\n",
        "# Justification: Compound scaling balances depth, width, and resolution for efficiency and accuracy. Pre-trained on ImageNet, optimized for limited compute; ReLU and softmax.\n",
        "eff_base = applications.EfficientNetB0(weights='imagenet', include_top=False, input_shape=(*IMG_SIZE, 3))\n",
        "model4, history4 = build_train_evaluate_model(eff_base, 'EfficientNetB0')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXHbzWVhIWF5",
        "outputId": "9b192315-a3a3-4f15-8c79-7a724912cb0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m1978/1978\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411ms/step - accuracy: 0.1220 - loss: 3.2348 - precision: 0.6216 - recall: 0.0268"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1978/1978\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m850s\u001b[0m 425ms/step - accuracy: 0.1221 - loss: 3.2345 - precision: 0.6217 - recall: 0.0268 - val_accuracy: 0.5532 - val_loss: 1.4940 - val_precision: 0.7641 - val_recall: 0.3885 - learning_rate: 0.0010\n",
            "Epoch 2/20\n",
            "\u001b[1m1978/1978\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398ms/step - accuracy: 0.5159 - loss: 1.5896 - precision: 0.7349 - recall: 0.3364"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1978/1978\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m814s\u001b[0m 412ms/step - accuracy: 0.5159 - loss: 1.5895 - precision: 0.7349 - recall: 0.3364 - val_accuracy: 0.7439 - val_loss: 0.8208 - val_precision: 0.8304 - val_recall: 0.6545 - learning_rate: 0.0010\n",
            "Epoch 3/20\n",
            "\u001b[1m1978/1978\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396ms/step - accuracy: 0.6810 - loss: 1.0316 - precision: 0.8043 - recall: 0.5604"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1978/1978\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m808s\u001b[0m 408ms/step - accuracy: 0.6810 - loss: 1.0315 - precision: 0.8043 - recall: 0.5604 - val_accuracy: 0.8227 - val_loss: 0.5624 - val_precision: 0.8790 - val_recall: 0.7674 - learning_rate: 0.0010\n",
            "Epoch 4/20\n",
            "\u001b[1m1978/1978\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401ms/step - accuracy: 0.7457 - loss: 0.8151 - precision: 0.8334 - recall: 0.6602"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1978/1978\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m819s\u001b[0m 414ms/step - accuracy: 0.7457 - loss: 0.8150 - precision: 0.8334 - recall: 0.6602 - val_accuracy: 0.8452 - val_loss: 0.4827 - val_precision: 0.8878 - val_recall: 0.8076 - learning_rate: 0.0010\n",
            "Epoch 5/20\n",
            "\u001b[1m1978/1978\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392ms/step - accuracy: 0.7799 - loss: 0.6970 - precision: 0.8514 - recall: 0.7134"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1978/1978\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m800s\u001b[0m 405ms/step - accuracy: 0.7799 - loss: 0.6970 - precision: 0.8514 - recall: 0.7134 - val_accuracy: 0.8433 - val_loss: 0.4739 - val_precision: 0.8767 - val_recall: 0.8098 - learning_rate: 0.0010\n",
            "Epoch 6/20\n",
            "\u001b[1m1978/1978\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394ms/step - accuracy: 0.8058 - loss: 0.6150 - precision: 0.8665 - recall: 0.7508"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1978/1978\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m804s\u001b[0m 406ms/step - accuracy: 0.8058 - loss: 0.6150 - precision: 0.8665 - recall: 0.7508 - val_accuracy: 0.8770 - val_loss: 0.3947 - val_precision: 0.9007 - val_recall: 0.8556 - learning_rate: 0.0010\n",
            "Epoch 7/20\n",
            "\u001b[1m1978/1978\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393ms/step - accuracy: 0.8233 - loss: 0.5593 - precision: 0.8742 - recall: 0.7743"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1978/1978\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m803s\u001b[0m 406ms/step - accuracy: 0.8233 - loss: 0.5593 - precision: 0.8742 - recall: 0.7743 - val_accuracy: 0.9064 - val_loss: 0.2861 - val_precision: 0.9244 - val_recall: 0.8866 - learning_rate: 0.0010\n",
            "Epoch 8/20\n",
            "\u001b[1m1978/1978\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392ms/step - accuracy: 0.8325 - loss: 0.5274 - precision: 0.8803 - recall: 0.7885"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1978/1978\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m801s\u001b[0m 405ms/step - accuracy: 0.8325 - loss: 0.5274 - precision: 0.8803 - recall: 0.7885 - val_accuracy: 0.9103 - val_loss: 0.2716 - val_precision: 0.9328 - val_recall: 0.8905 - learning_rate: 0.0010\n",
            "Epoch 9/20\n",
            "\u001b[1m1978/1978\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m805s\u001b[0m 407ms/step - accuracy: 0.8490 - loss: 0.4803 - precision: 0.8885 - recall: 0.8121 - val_accuracy: 0.9107 - val_loss: 0.2733 - val_precision: 0.9272 - val_recall: 0.8953 - learning_rate: 0.0010\n",
            "Epoch 10/20\n",
            "\u001b[1m1978/1978\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392ms/step - accuracy: 0.8551 - loss: 0.4682 - precision: 0.8932 - recall: 0.8199"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1978/1978\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m800s\u001b[0m 404ms/step - accuracy: 0.8551 - loss: 0.4682 - precision: 0.8932 - recall: 0.8199 - val_accuracy: 0.9143 - val_loss: 0.2667 - val_precision: 0.9308 - val_recall: 0.8990 - learning_rate: 0.0010\n",
            "Epoch 11/20\n",
            "\u001b[1m1978/1978\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m802s\u001b[0m 405ms/step - accuracy: 0.8648 - loss: 0.4344 - precision: 0.8994 - recall: 0.8329 - val_accuracy: 0.8786 - val_loss: 0.3899 - val_precision: 0.8983 - val_recall: 0.8631 - learning_rate: 0.0010\n",
            "Epoch 12/20\n",
            "\u001b[1m1978/1978\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396ms/step - accuracy: 0.8662 - loss: 0.4291 - precision: 0.8998 - recall: 0.8380"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1978/1978\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m810s\u001b[0m 410ms/step - accuracy: 0.8662 - loss: 0.4291 - precision: 0.8998 - recall: 0.8380 - val_accuracy: 0.9409 - val_loss: 0.1833 - val_precision: 0.9518 - val_recall: 0.9303 - learning_rate: 0.0010\n",
            "Epoch 13/20\n",
            "\u001b[1m1978/1978\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m799s\u001b[0m 404ms/step - accuracy: 0.8696 - loss: 0.4193 - precision: 0.9013 - recall: 0.8412 - val_accuracy: 0.9261 - val_loss: 0.2274 - val_precision: 0.9418 - val_recall: 0.9138 - learning_rate: 0.0010\n",
            "Epoch 14/20\n",
            "\u001b[1m1978/1978\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m797s\u001b[0m 403ms/step - accuracy: 0.8721 - loss: 0.4048 - precision: 0.9027 - recall: 0.8441 - val_accuracy: 0.9306 - val_loss: 0.2154 - val_precision: 0.9433 - val_recall: 0.9190 - learning_rate: 0.0010\n",
            "Epoch 15/20\n",
            "\u001b[1m1978/1978\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m811s\u001b[0m 410ms/step - accuracy: 0.8784 - loss: 0.3953 - precision: 0.9067 - recall: 0.8540 - val_accuracy: 0.9364 - val_loss: 0.2073 - val_precision: 0.9455 - val_recall: 0.9282 - learning_rate: 0.0010\n",
            "Epoch 16/20\n",
            "\u001b[1m1978/1978\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392ms/step - accuracy: 0.9099 - loss: 0.2851 - precision: 0.9296 - recall: 0.8937"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1978/1978\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m802s\u001b[0m 405ms/step - accuracy: 0.9099 - loss: 0.2850 - precision: 0.9297 - recall: 0.8937 - val_accuracy: 0.9577 - val_loss: 0.1293 - val_precision: 0.9636 - val_recall: 0.9519 - learning_rate: 2.0000e-04\n",
            "Epoch 17/20\n",
            "\u001b[1m1978/1978\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400ms/step - accuracy: 0.9213 - loss: 0.2507 - precision: 0.9374 - recall: 0.9067"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1978/1978\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m816s\u001b[0m 413ms/step - accuracy: 0.9213 - loss: 0.2507 - precision: 0.9374 - recall: 0.9067 - val_accuracy: 0.9602 - val_loss: 0.1175 - val_precision: 0.9658 - val_recall: 0.9558 - learning_rate: 2.0000e-04\n",
            "Epoch 18/20\n",
            "\u001b[1m1978/1978\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m820s\u001b[0m 414ms/step - accuracy: 0.9236 - loss: 0.2359 - precision: 0.9391 - recall: 0.9087 - val_accuracy: 0.9536 - val_loss: 0.1453 - val_precision: 0.9593 - val_recall: 0.9480 - learning_rate: 2.0000e-04\n",
            "Epoch 19/20\n",
            "\u001b[1m1978/1978\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m827s\u001b[0m 418ms/step - accuracy: 0.9280 - loss: 0.2251 - precision: 0.9408 - recall: 0.9154 - val_accuracy: 0.9474 - val_loss: 0.1594 - val_precision: 0.9540 - val_recall: 0.9420 - learning_rate: 2.0000e-04\n",
            "Epoch 20/20\n",
            "\u001b[1m 582/1978\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9:19\u001b[0m 401ms/step - accuracy: 0.9324 - loss: 0.2141 - precision: 0.9456 - recall: 0.9204"
          ]
        }
      ]
    }
  ]
}